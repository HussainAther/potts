{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wEsF7vQhpyv"
   },
   "source": [
    "# Training Potts Models with Contrastive Divergence for Protein Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bzFaRlhh3z3"
   },
   "source": [
    "## GREMLIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0DZPw7CjbO0"
   },
   "source": [
    "https://github.com/whbpt/GREMLIN_PYTORCH/blob/master/GREMLIN_pytorch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNLsuDzLYxow"
   },
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6gNrodvGYw1r"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT, only tested using PYTHON 3!\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vThmAX0OZElD"
   },
   "source": [
    "#### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OEw4keeiZD3A"
   },
   "outputs": [],
   "source": [
    "################\n",
    "# note: if you are modifying the alphabet\n",
    "# make sure last character is \"-\" (gap)\n",
    "################\n",
    "alphabet = \"ARNDCQEGHILKMFPSTWYV-\"\n",
    "states = len(alphabet)\n",
    "a2n = {}\n",
    "for a,n in zip(alphabet,range(states)):\n",
    "  a2n[a] = n\n",
    "################\n",
    "\n",
    "def aa2num(aa):\n",
    "  '''convert aa into num'''\n",
    "  if aa in a2n: return a2n[aa]\n",
    "  else: return a2n['-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LxTBUUtthlo3"
   },
   "outputs": [],
   "source": [
    "## Convert FASTA to MSA np.array()\n",
    "\n",
    "def parse_fasta(filename):\n",
    "  '''function to parse fasta file'''\n",
    "  header = []\n",
    "  sequence = []\n",
    "  lines = open(filename, \"r\")\n",
    "  for line in lines:\n",
    "    line = line.rstrip()\n",
    "    if line[0] == \">\":\n",
    "      header.append(line[1:])\n",
    "      sequence.append([])\n",
    "    else:\n",
    "      sequence[-1].append(line)\n",
    "  lines.close()\n",
    "  sequence = [''.join(seq) for seq in sequence]\n",
    "  return np.array(header), np.array(sequence)\n",
    "\n",
    "def one_hot(msa,states):\n",
    "  one = np.eye(states)\n",
    "  return one[msa]\n",
    "\n",
    "def mk_msa(seqs):\n",
    "  '''one hot encode msa'''\n",
    "  \n",
    "  ################\n",
    "  alphabet = \"ARNDCQEGHILKMFPSTWYV-\"\n",
    "  states = len(alphabet)\n",
    "  a2n = {}\n",
    "  for a,n in zip(alphabet,range(states)):\n",
    "    a2n[a] = n\n",
    "\n",
    "  def aa2num(aa):\n",
    "    '''convert aa into num'''\n",
    "    if aa in a2n: return a2n[aa]\n",
    "    else: return a2n['-']\n",
    "  ################\n",
    "  \n",
    "  msa = []\n",
    "  for seq in seqs:\n",
    "    msa.append([aa2num(aa) for aa in seq])\n",
    "  msa_ori = np.array(msa)\n",
    "  return msa_ori, one_hot(msa_ori,states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AU2C8jFKTHTj",
    "outputId": "6fa97284-0241-4a76-ff01-db05e6b56dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 113)\n",
      "(48, 113, 21)\n"
     ]
    }
   ],
   "source": [
    "names,seqs = parse_fasta(\"pfamncamseed.fas.txt\")\n",
    "msa_ori, msa = mk_msa(seqs)\n",
    "\n",
    "print(msa_ori.shape)\n",
    "print(msa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "I1neFyOt0c9i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 113 bases\n"
     ]
    }
   ],
   "source": [
    "# collecting some information about input msa\n",
    "N = msa.shape[0] # number of sequences\n",
    "L = msa.shape[1] # length of sequence\n",
    "A = msa.shape[2] # number of states (or categories)\n",
    "print(\"length \" + str(L) + \" bases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "doEHZ4Y4WihF"
   },
   "outputs": [],
   "source": [
    "class GREMLIN(torch.nn.Module):\n",
    "  def __init__(self,L,A):\n",
    "    super(GREMLIN, self).__init__()\n",
    "    self.W0 = torch.nn.Parameter(torch.zeros(L*A,L*A), requires_grad=True) # this is J in the manuscript\n",
    "    self.b0 = torch.nn.Parameter(torch.zeros(L*A), requires_grad=True) # this is H \n",
    "    self.MASK = (1.0 -torch.eye(L*A))\n",
    "    \n",
    "  def forward(self,X):\n",
    "    X = X.reshape(-1,L*A)\n",
    "    W = (self.W0+self.W0)/2.0 * self.MASK\n",
    "    MSA_pred = (X.mm(W)+self.b0).reshape(-1,L,A)\n",
    "    loss = torch.sum(- MSA_Input * F.log_softmax(MSA_pred, -1))\n",
    "    L2_w = (W**2).sum() * 0.01 * 0.5 *L*A\n",
    "    L2_b = (self.b0**2).sum() * 0.01\n",
    "    loss = loss + L2_w + L2_b\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eCiwYPpnWosa"
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "  def __init__(self,L,A):\n",
    "    super(Model, self).__init__()\n",
    "    self.GREMLIN_ = GREMLIN(L,A)\n",
    "    \n",
    "  def forward(self,X):\n",
    "    loss = self.GREMLIN_(X)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3aLsVsZQWsR9",
    "outputId": "7042e759-34e9-4b8f-cafb-2091816cdb06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16513.498046875\n",
      "10 7362.86572265625\n",
      "20 6565.06982421875\n",
      "30 6130.17431640625\n",
      "40 5972.72900390625\n",
      "50 5892.46337890625\n",
      "60 5841.9091796875\n",
      "70 5809.32177734375\n",
      "80 5783.7626953125\n",
      "90 5762.48681640625\n"
     ]
    }
   ],
   "source": [
    "#enviroment setting\n",
    "device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "MSA_Input = torch.from_numpy(msa.astype(np.float32))\n",
    "\n",
    "model = Model(L,A)\n",
    "learning_rate = 0.1*np.log(N)/L\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for t in range(100):\n",
    "\n",
    "    loss = model(MSA_Input)      \n",
    "    optimizer.zero_grad()    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (t) % (int(100/10)) == 0: \n",
    "      print(t, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "d-7x7L5FXHtC"
   },
   "outputs": [],
   "source": [
    "w = model.GREMLIN_.W0.detach().numpy()\n",
    "w = (w+w.T).reshape(L,A,L,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlA83qkgXuEB",
    "outputId": "c93ddeed-b7ca-4e56-c725-dcc2afc83d03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5743.4326, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(MSA_Input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2728, 1.0324, 0.8322,  ..., 0.8424, 1.1481, 0.8424],\n",
      "        [1.2696, 1.0345, 0.8324,  ..., 0.8425, 1.1448, 0.8425],\n",
      "        [1.2728, 1.0345, 0.8328,  ..., 0.8426, 1.1377, 0.8426],\n",
      "        ...,\n",
      "        [1.2728, 1.0345, 0.8328,  ..., 0.8426, 1.1377, 0.8426],\n",
      "        [1.3004, 1.0458, 0.8258,  ..., 0.8374, 1.1377, 0.8374],\n",
      "        [1.2728, 1.0345, 0.8328,  ..., 0.8426, 1.1377, 0.8426]],\n",
      "       grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Use the equation for probability of Boltzmann distribution \n",
    "#(without the 1/Z term) to calculate likelihood.\n",
    "boltzprob = torch.exp(model.GREMLIN_.b0 + model.GREMLIN_.W0)\n",
    "print(boltzprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'boltzprob'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(boltzprob + \".pkl\",outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15047, 227)\n",
      "(15047, 227, 21)\n"
     ]
    }
   ],
   "source": [
    "names,seqs = parse_fasta(\"lcc_short.fasta\")\n",
    "msa_ori, msa = mk_msa(seqs)\n",
    "\n",
    "print(msa_ori.shape)\n",
    "print(msa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 227 bases\n"
     ]
    }
   ],
   "source": [
    "# collecting some information about input msa\n",
    "N = msa.shape[0] # number of sequences\n",
    "L = msa.shape[1] # length of sequence\n",
    "A = msa.shape[2] # number of states (or categories)\n",
    "print(\"length \" + str(L) + \" bases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10394716.0\n",
      "10 3939189.0\n",
      "20 3186403.25\n",
      "30 2812765.25\n",
      "40 2597935.0\n",
      "50 2468500.25\n",
      "60 2385217.25\n",
      "70 2326635.5\n",
      "80 2282482.25\n",
      "90 2247493.25\n"
     ]
    }
   ],
   "source": [
    "#enviroment setting\n",
    "device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "MSA_Input = torch.from_numpy(msa.astype(np.float32))\n",
    "\n",
    "model = Model(L,A)\n",
    "learning_rate = 0.1*np.log(N)/L\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for t in range(100):\n",
    "\n",
    "    loss = model(MSA_Input)      \n",
    "    optimizer.zero_grad()    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (t) % (int(100/10)) == 0: \n",
    "      print(t, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.GREMLIN_.W0.detach().numpy()\n",
    "w = (w+w.T).reshape(L,A,L,A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2218766.7500, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(MSA_Input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9831255 , 0.7342316 , 0.8396671 , ..., 0.9933628 , 0.9507758 ,\n",
       "        1.0254905 ],\n",
       "       [0.74140203, 0.9745842 , 0.84978044, ..., 0.9399867 , 0.99189085,\n",
       "        1.0085703 ],\n",
       "       [0.84392446, 0.8449259 , 0.9814686 , ..., 0.94934356, 1.003612  ,\n",
       "        0.98447824],\n",
       "       ...,\n",
       "       [1.0004965 , 0.947467  , 0.95469993, ..., 0.97717494, 0.9197535 ,\n",
       "        0.86047524],\n",
       "       [0.95039135, 0.95212907, 0.98805827, ..., 0.914793  , 0.986301  ,\n",
       "        0.7765249 ],\n",
       "       [0.9701704 , 0.95416856, 0.94302356, ..., 0.897725  , 0.8195636 ,\n",
       "        1.0187222 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the equation for probability of Boltzmann distribution \n",
    "#(without the 1/Z term) to calculate likelihood.\n",
    "boltzprob = torch.exp(model.GREMLIN_.b0 + model.GREMLIN_.W0)\n",
    "boltzprob.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"lccboltzprob.npy\", boltzprob.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70cuqoEwh6ua"
   },
   "source": [
    "### bmDCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S4NieuvpK-d"
   },
   "source": [
    "**Important Notes:**\n",
    "\n",
    "*  All amino acids must be upper case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uycScwLXjYcY"
   },
   "source": [
    "https://github.com/ranganathanlab/bmDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsbIeBcAh7nS",
    "outputId": "ddba39af-b8a0-427e-a749-9a7214c150c4"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ranganathanlab/bmDCA.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGA3ExkIhWqr",
    "outputId": "d6f07131-230f-4ae6-ad03-37d38c4cde0c"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install git gcc g++ automake autoconf pkg-config \\\n",
    "  libarmadillo-dev libopenblas-dev libarpack++2-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PD6EtSWehGYj",
    "outputId": "b3ca3579-e8d9-4408-bece-cea098143b23"
   },
   "outputs": [],
   "source": [
    "%cd bmDCA\n",
    "!bash autogen.sh --prefix=/usr/local && \\\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqzOKukDkVqY",
    "outputId": "7fe9ad5d-935d-40a9-9296-7340a81df079"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "cd bmDCA\n",
    "make -j4 && \\\n",
    "make install\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQmkeiO5lbNv"
   },
   "outputs": [],
   "source": [
    "!mkdir results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0uj1pjNl1yd"
   },
   "outputs": [],
   "source": [
    "!cp pfam_hits.txt lcc.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bqAs-8fpxVE"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pq7whj-FsI4o"
   },
   "source": [
    "100-245 of LCC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DN2UippGv2Jl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_fasta(fname):\n",
    "    seqs = []\n",
    "    s = \"\"\n",
    "    with open(fname) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            if line.startswith(\">\"):\n",
    "                if s != \"\":\n",
    "                    seqs.append(list(s))\n",
    "                s = \"\"\n",
    "            elif len(line) > 0:\n",
    "                s += line.strip()\n",
    "            line = f.readline()\n",
    "        seqs.append(list(s))\n",
    "    return np.array(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69iTRXtwP33q"
   },
   "outputs": [],
   "source": [
    "seqs = read_fasta(\"pfam_hits.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jw8kY_Z7QWtz"
   },
   "outputs": [],
   "source": [
    "mask = np.zeros(len(seqs[0]), dtype=np.bool)\n",
    "for i in range(len(seqs[0])):\n",
    "    gaps = 0\n",
    "    for s in seqs:\n",
    "        if s[i] == '-':\n",
    "            gaps += 1\n",
    "    if gaps/len(seqs) < 0.67:   # keep positions where less that 2/3rd are gaps\n",
    "        mask[i] = True\n",
    "seqs = seqs[:,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DNBiArLSgj4"
   },
   "outputs": [],
   "source": [
    "towrite = \"\"\n",
    "for i in range(len(seqs)):\n",
    "    towrite += \">{}\\n\".format(i)\n",
    "    towrite += \"\".join(seqs[i][100:]) + \"\\n\"   # take positions 100-226\n",
    "with open(\"lcc_short.fasta\",'w') as f:\n",
    "    f.write(towrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sqs_m0ikIhlJ",
    "outputId": "ca15834c-f905-4482-b44f-cb7d2f3dd579"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "rm results/*\n",
    "bmdca -i lcc_short.fasta -r -d /content/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSQpLadwrr0U"
   },
   "outputs": [],
   "source": [
    "!tar -czf boltzmann.tar.gz results/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jVoi1llpyxy"
   },
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q27911vyqJQB"
   },
   "source": [
    "Change temperature in a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yddxIEnwm_xx"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "bmdca_sample -p parameters.txt -d /content/results -o samples.txt -c config.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "diPkGaKsmo7u",
    "outputId": "1b5170ec-1b41-4b15-dfd1-758811a7b4e1"
   },
   "outputs": [],
   "source": [
    "!perl convert.pl lcc_pfam.txt lcc_pfam.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ9dXZ5yh8Kb"
   },
   "source": [
    "### Contrastive Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EkD-Lc-Dh9S9"
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax import grad\n",
    "from jax.scipy.stats.norm import pdf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "key = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8U_SNKzh-_w"
   },
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2AVm-RCiAkp"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/igemto-drylab/CSBERG-ML.git\n",
    "%cd CSBERG-ML\n",
    "from util import *"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CSC412_Potts_Proteins_hussain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
